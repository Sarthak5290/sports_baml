/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "// Client configuration - using Groq via OpenAI-compatible endpoint\r\nclient<llm> GroqClient {\r\n  provider \"openai\"\r\n  options {\r\n    base_url \"https://api.groq.com/openai/v1\"\r\n    model \"llama-3.1-70b-versatile\"\r\n    api_key env.GROQ_API_KEY\r\n  }\r\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.89.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "resume.baml": "// Defining a data model.\r\nclass Resume {\r\n  name string\r\n  email string\r\n  experience string[]\r\n  skills string[]\r\n}\r\n\r\n// Create a function to extract the resume from a string.\r\nfunction ExtractResume(resume: string) -> Resume {\r\n  // Specify a client as provider/model-name\r\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\r\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\r\n  prompt #\"\r\n    Extract from this content:\r\n    {{ resume }}\r\n\r\n    {{ ctx.output_format }}\r\n  \"#\r\n}\r\n\r\n\r\n\r\n// Test the function with a sample resume. Open the VSCode playground to run this.\r\ntest vaibhav_resume {\r\n  functions [ExtractResume]\r\n  args {\r\n    resume #\"\r\n      Vaibhav Gupta\r\n      vbv@boundaryml.com\r\n\r\n      Experience:\r\n      - Founder at BoundaryML\r\n      - CV Engineer at Google\r\n      - CV Engineer at Microsoft\r\n\r\n      Skills:\r\n      - Rust\r\n      - C++\r\n    \"#\r\n  }\r\n}\r\n",
  "sports.baml": "// Define the data structure for sport information\r\nclass SportInfo {\r\n  name string\r\n  description string\r\n  origin string\r\n  equipment string[]\r\n  players_count string\r\n  fun_facts string[]\r\n}\r\n\r\n// BAML function to get sport information\r\nfunction GetSportInfo(sport_name: string) -> SportInfo {\r\n  client GroqClient\r\n  prompt #\"\r\n    You are a sports expert. Given a sport name, provide comprehensive information about it.\r\n    \r\n    Sport: {{sport_name}}\r\n    \r\n    Please provide detailed information about this sport including:\r\n    - A clear description of how the sport is played\r\n    - The origin/history of the sport\r\n    - Equipment needed\r\n    - Number of players typically involved\r\n    - Interesting fun facts\r\n    \r\n    Make sure your response is informative, accurate, and engaging.\r\n    \r\n    {{ ctx.output_format }}\r\n  \"#\r\n}",
}
export const getBamlFiles = () => {
    return fileMap;
}